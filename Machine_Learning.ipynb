{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google Drive and Import Libraries**\n",
        "\n",
        "\n",
        "\n",
        "*   Mount Google Drive: Connects your Google Drive to Google Colab to access    files stored there.\n",
        "*   Import Libraries: Loads various libraries used for data analysis, machine learning modeling, visualization, and geospatial analysis, such as pandas, tensorflow, matplotlib, plotly, and others.\n",
        "\n"
      ],
      "metadata": {
        "id": "0Cv2IVq3QazA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHhANRleQS9w"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "!pip install tensorflow==2.15\n",
        "!pip install plotly_express\n",
        "!pip install openpyxl\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "import plotly_express as px\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, accuracy_score\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "from math import radians\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset and Inspect Data**\n",
        "\n",
        "\n",
        "*   Load Data: Reads the dataset from the Excel file stored in your Google Drive.\n",
        "*   Inspect Data: Displays the first few rows of the dataset to check its structure.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mdjc532TQxBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = r'/content/drive/MyDrive/capstone/dataset.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "uw_G0eQAQu3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detect and Remove Outliers**\n",
        "\n",
        "\n",
        "\n",
        "Outlier Detection: Uses the Interquartile Range (IQR) method to detect outliers in the latitude and longitude columns.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "smxXiXhzRCHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect outliers in latitude and longitude columns using IQR (Interquartile Range) method\n",
        "Q1 = df['latitude'].quantile(0.25)\n",
        "Q3 = df['latitude'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "outliers = df[(df['latitude'] < lower_bound) | (df['latitude'] > upper_bound)]\n",
        "\n",
        "Q1 = df['longitude'].quantile(0.25)\n",
        "Q3 = df['longitude'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "outliers = df[(df['longitude'] < lower_bound) | (df['longitude'] > upper_bound)]\n"
      ],
      "metadata": {
        "id": "6Kw9DwWgQ_mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize Latitude and Longitude**\n",
        "\n",
        "Data Visualization: Creates a scatter plot to visualize the distribution of data based on latitude and longitude.\n",
        "\n"
      ],
      "metadata": {
        "id": "ntXoa_fMRUQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df['longitude'], df['latitude'])\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Scatter Plot of Latitude and Longitude')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gLXJD-tiRhP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize Historical Category Distribution**\n",
        "\n",
        "Category Visualization: Creates a bar chart to visualize the distribution of historical categories in the dataset."
      ],
      "metadata": {
        "id": "LGuP4hvLRlyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kategori_counts = df['kategori sejarah'].astype(str).str.lower().value_counts()\n",
        "kategori_counts = kategori_counts.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(kategori_counts.index, kategori_counts.values)\n",
        "plt.xlabel('Kategori Sejarah')\n",
        "plt.ylabel('Jumlah')\n",
        "plt.title('Grafik Data Berdasarkan Kategori Sejarah')\n",
        "plt.xticks(rotation=0, ha='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cKB6OTd6Rrty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Means Clustering Based on Latitude and Longitude**\n",
        "\n",
        "K-Means Clustering: Applies K-Means clustering on the latitude and longitude data to group locations into 5 clusters, and evaluates the clustering accuracy by comparing the predicted clusters to the true labels."
      ],
      "metadata": {
        "id": "9vdj18pDRu8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['latitude', 'longitude']].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['lokasi_encoded'] = label_encoder.fit_transform(df['Lokasi'])\n",
        "y_true = df['lokasi_encoded'].values\n",
        "\n",
        "cluster_mapping = {\n",
        "    0: 'Jakarta Pusat',\n",
        "    1: 'Jakarta Timur',\n",
        "    2: 'Jakarta Utara',\n",
        "    3: 'Jakarta Barat',\n",
        "    4: 'Jakarta Selatan'\n",
        "}\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, random_state=0, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(X)\n",
        "df['predicted_lokasi'] = df['cluster'].map(cluster_mapping)\n",
        "\n",
        "accuracy = accuracy_score(y_true, df['cluster'])\n",
        "print(f\"Clustering Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "HGfIRsIkR0u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize Clusters on a Map**\n",
        "\n",
        "Map Visualization: Uses Plotly to create an interactive map, visualizing the clustering results based on latitude and longitude."
      ],
      "metadata": {
        "id": "7wxQGjFDR3L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter_mapbox(df, lat=\"latitude\", lon=\"longitude\", color=\"predicted_lokasi\",\n",
        "                        zoom=10, height=600, width=800,\n",
        "                        mapbox_style=\"carto-positron\",\n",
        "                        title=\"Jakarta Regions based on Latitude and Longitude\")\n",
        "fig.update_layout(mapbox_zoom=10, mapbox_center={\"lat\": df['latitude'].mean(), \"lon\": df['longitude'].mean()})\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "dfaMvOObR-3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find Nearest Data Points Using Haversine Distance**\n",
        "\n",
        "Find Nearest Data Points: Defines a function to find the nearest data points to a given test point using the Haversine formula to calculate distances based on latitude and longitude."
      ],
      "metadata": {
        "id": "aCMPGTOFSAr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nearest_data_points(test_latitude, test_longitude, df, n_neighbors=3):\n",
        "    test_point = np.array([[radians(test_latitude), radians(test_longitude)]])\n",
        "    df['lat_rad'] = np.radians(df['latitude'])\n",
        "    df['lon_rad'] = np.radians(df['longitude'])\n",
        "    distances = haversine_distances(test_point, df[['lat_rad', 'lon_rad']].values) * 6371  # Earth's radius in km\n",
        "    df['distance'] = distances[0]\n",
        "    nearest_data = df.sort_values(by='distance').head(n_neighbors)\n",
        "    return nearest_data\n"
      ],
      "metadata": {
        "id": "tQoSo3bSSHSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Data for TensorFlow Model**\n",
        "\n",
        "Prepare Data for Training: Prepares the feature variables (latitude, longitude) and the target variable (cluster). The features are normalized using StandardScaler."
      ],
      "metadata": {
        "id": "F_UUip-LSI3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['latitude', 'longitude']].values\n",
        "y = df['cluster'].values\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "GFCvpmneSO7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build and Train a Neural Network Model**\n",
        "\n",
        "Build Neural Network Model: Constructs a neural network using Keras. The network consists of multiple dense layers and dropout layers to prevent overfitting. It uses the softmax activation function for multi-class classification and sparse_categorical_crossentropy for the loss function."
      ],
      "metadata": {
        "id": "2ISy0Yl7STly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.InputLayer(input_shape=(2,)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X, y, epochs=40, batch_size=8, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "e1oadi5fSRP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make Predictions with the Mode**\n",
        "\n",
        "Prediction: Uses the trained model to predict the cluster of a new test point."
      ],
      "metadata": {
        "id": "K-dIp__EScyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_point_for_model = scaler.transform(np.array([[test_point[0], test_point[1]]]))\n",
        "predicted_cluster = model.predict(test_point_for_model)\n",
        "predicted_cluster\n"
      ],
      "metadata": {
        "id": "-I-hShLKSiX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Model**\n",
        "\n",
        "Random Forest: Implements a Random Forest classifier to predict the region for a new test point based on latitude and longitude."
      ],
      "metadata": {
        "id": "_4DXUKiNSkBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "test_point = (-6.146975375216407, 106.75060382943789)\n",
        "predicted_region = model.predict([test_point])\n",
        "print(\"Predicted Region:\", predicted_region)\n"
      ],
      "metadata": {
        "id": "PAF7CZ3YSusT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model**\n",
        "\n",
        "Model Evaluation: Evaluates the model on the training data and prints the loss and accuracy metrics."
      ],
      "metadata": {
        "id": "BT89Ug-6TA6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "1IjDAuxZTHee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the Model and Convert to TensorFlow.js Format**\n",
        "\n",
        "Save and Convert Model: Saves the trained model and converts it into TensorFlow.js format to be used in web applications."
      ],
      "metadata": {
        "id": "bZU2Im6HTJY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = \"./my_model.h5\"\n",
        "model.save(saved_model_path)\n",
        "\n",
        "!pip install tensorflow_decision_forests==1.8.1\n",
        "\n",
        "!tensorflowjs_converter \\\n",
        "    --input_format=keras \\\n",
        "    {saved_model_path} \\\n",
        "    \"./\"\n",
        "\n",
        "!zip model.zip *.bin model.json\n"
      ],
      "metadata": {
        "id": "F2aRj7EGTPbG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}